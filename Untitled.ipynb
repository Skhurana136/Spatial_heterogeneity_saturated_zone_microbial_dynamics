{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Mixed Effects Modeling\n",
    "\n",
    "## Identify which are the best factors that can aid in prediction of mass removal\n",
    "## What are the best substitutes for them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data directory and file sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"Y:/Home/khurana/4. Publications/Restructuring/Paper2/Figurecodes/\"\n",
    "head_path = \"headatinlet.csv\"\n",
    "RMSamp_path = \"Normalized_RMSamplitude_chem.csv\"\n",
    "sensitivity_path = \"mass_flux_sensitivity_generalized.csv\"\n",
    "da_path = \"Conc_da_ss.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_data = pd.read_csv(os.path.join(data_dir, head_path), sep = \",\")\n",
    "RMSamp_data = pd.read_csv(os.path.join(data_dir, RMSamp_path), sep = \"\\t\")\n",
    "sensitivity_data = pd.read_csv(os.path.join(data_dir, sensitivity_path), sep = \"\\t\")\n",
    "da_data = pd.read_csv(os.path.join(data_dir, da_path), sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consider and calculate imposed time series information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate covariance of imposed time series\n",
    "cov1 = np.round(np.cov(head_data[\"H1\"]),2)\n",
    "cov2 = np.round(np.cov(head_data[\"H2\"]),2)\n",
    "cov3 = np.round(np.cov(head_data[\"H3\"]),2)\n",
    "\n",
    "#Calculate correlation of imposed time series\n",
    "def corrfunc (data):\n",
    "    normdata = data - np.mean(data)\n",
    "    autocorr_f = (np.correlate(normdata, normdata, mode='full'))/(np.std(data)**2 * np.shape(data)[0])\n",
    "    return autocorr_f\n",
    "\n",
    "cor1 = corrfunc(head_data[\"H1\"])[5474:]\n",
    "cor2 = corrfunc(head_data[\"H2\"])[5474:]\n",
    "cor3 = corrfunc(head_data[\"H3\"])[5474:]\n",
    "\n",
    "#Calculate time point where the correlation drops below 0.75 (Threshold value for a strong correlation)\n",
    "cor1tim = np.where(cor1 < 0.75)[0][0]\n",
    "cor2tim = np.where(cor2 < 0.75)[0][0]\n",
    "cor3tim = np.where(cor3 < 0.75)[0][0]\n",
    "mincor = cor2.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate RMS amplitude data and sensitivity data sets to include additional information of time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanup_tim = {\"cov\" : {1 : cov1, 2 : cov2, 5 : cov3},\n",
    "               \"timtrace\" : {1 : cor1tim, 2: cor2tim, 5 : cor3tim},\n",
    "               \"chem_factors\" : {'DOC':0,'DO':1, 'Ammonium':2, 'Nitrate':3, 'Sulphate':4, 'Particulate organic matter':5,\n",
    "                                 'Mobile active aerobic degraders':6, 'Mobile active nitrate reducers':7,\n",
    "                                 'Mobile active sulphate reducers':8, 'Mobile active ammonia oxidizers':9,\n",
    "                                 'Mobile inactive aerobic degraders':10, 'Mobile inactive nitrate reducers':11,\n",
    "                                 'Mobile inactive sulphate reducers':12, 'Mobile inactive ammonia oxidizers':13,\n",
    "                                 'Nitrogen':14, 'TOC':15},\n",
    "                   \"Pe\" : {'Slow':2,'Medium':11, 'Fast':22}}\n",
    "\n",
    "print(RMSamp_data.columns)\n",
    "print(RMSamp_data.shape)\n",
    "print(RMSamp_data.Chem.unique())\n",
    "RMSamp_data[\"Regime\"] = RMSamp_data[\"Regime\"].replace([\"Equal\"], \"Medium\")\n",
    "chemstoplot = [\"DOC\", \"DO\", \"TOC\", \"Nitrogen\"]\n",
    "RMSamp_data[\"cov\"] = RMSamp_data [\"Time_series\"]\n",
    "\n",
    "sensitivity_data[\"timtrace\"] = sensitivity_data [\"Time_series\"]\n",
    "sensitivity_data[\"chem_factors\"] = sensitivity_data [\"Chem\"]\n",
    "sensitivity_data[\"Pe\"] = sensitivity_data [\"Regime\"]\n",
    "sensitivity_data.replace(cleanup_tim, inplace = True)\n",
    "\n",
    "mdata = pd.merge(sensitivity_data, da_data[[\"Regime\", \"Trial\", \"Chem\", \"%reldelmassflux\", \"Breakthroughtime\", \"avgconc_in\"]], on = [\"Regime\", \"Trial\", \"Chem\"])\n",
    "mdata.loc[mdata[\"PeDa\"] > 40, \"PeDamark\"] = 3\n",
    "mdata.loc[(mdata[\"PeDa\"] > 20) & (mdata[\"PeDa\"] < 40), \"PeDamark\"] = 2\n",
    "mdata.loc[(mdata[\"PeDa\"] > 1) & (mdata[\"PeDa\"] < 20), \"PeDamark\"] = 1\n",
    "mdata.loc[mdata[\"PeDa\"] < 1, \"PeDamark\"] = 0\n",
    "labels = {0 : \"Da/Pe < 1\",\n",
    "          1 : \"1 < Da/Pe < 15\",\n",
    "          2 : \"15 < Da/Pe < 40\",\n",
    "          3 : \"Da/Pe > 40\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Transient\n",
    "allfeatures = dadata.columns.tolist()\n",
    "features = ['Variance', 'Anisotropy', 'Regime', 'Chem', 'Breakthroughtime', 'fraction', 'cov', 'PeDa', 'PeDamark']\n",
    "yfeature = ['Sensitivity', 'Sensitivitybase']\n",
    "\n",
    "mydata = mdata[features+yfeature]\n",
    "chemstoplot = [\"DOC\", \"DO\", \"Nitrogen\", \"TOC\"]\n",
    "mydata = mydata[mydata['Chem'].isin (chemstoplot)]\n",
    "mydata[\"Variance\"]= mydata[\"Variance\"].astype(str)\n",
    "mydata[\"Anisotropy\"]= mydata[\"Anisotropy\"].astype(str)\n",
    "\n",
    "colsymdict = {\"Slow\" : \"indianred\", \"Medium\" : \"g\", \"Fast\" : \"steelblue\",\n",
    "              \"DOC\": 'D', \"DO\" : '^', \"Nitrogen\" : 's', \"TOC\" : 'o'}\n",
    "\n",
    "#Plot yfeature with breakthrough time divided by regime, variance and anisotropy\n",
    "import seaborn as sns\n",
    "sns.pairplot(mydata, kind=\"scatter\", hue=\"Regime\", palette=colsymdict)\n",
    "\n",
    "#fixed effect - fraction\n",
    "#Random effect - Regime, covariance, \n",
    "xplot = \"fraction\"\n",
    "yplot = 'Sensitivitybase'\n",
    "y = mydata[yplot]\n",
    "\n",
    "row = []\n",
    "f1 = yplot + ' ~ ' + xplot\n",
    "for g in [\"Regime\", \"Variance\", \"Anisotropy\", \"cov\"]:\n",
    "    print(g)\n",
    "    mymd = smf.mixedlm(formula = f1, data = mydata, groups = mydata[g])\n",
    "    mdf = mymd.fit()\n",
    "    y_predict = mdf.fittedvalues\n",
    "    RMSE = np.sqrt(((y-y_predict)**2).mean())\n",
    "    row.append([yplot, xplot,g,RMSE, \"Fixed\"])\n",
    "\n",
    "g = \"Regime\"\n",
    "mymd = smf.mixedlm(formula = f1, data = mydata, groups = mydata[g], re_formula = '~' + xplot)\n",
    "mdf = mymd.fit()\n",
    "y_predict = mdf.fittedvalues\n",
    "RMSE = np.sqrt(((y-y_predict)**2).mean())\n",
    "row.append([yplot, xplot,g,RMSE, \"RandomFixed\"])\n",
    "\n",
    "mydata[\"R_V\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str)\n",
    "mydata[\"R_A\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Anisotropy\"].astype(str)\n",
    "mydata[\"V_A\"] = mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str)\n",
    "mydata[\"R_V_A\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str)\n",
    "mydata[\"R_V_C\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Chem\"]\n",
    "mydata[\"R_A_C\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"]\n",
    "mydata[\"V_A_C\"] = mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"]\n",
    "mydata[\"R_V_A_C\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"]\n",
    "mydata [\"R_C\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Chem\"]\n",
    "mydata[\"R_V_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"R_A_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"V_A_Co\"] = mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"R_V_A_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"R_V_C_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Chem\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"R_A_C_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"V_A_C_Co\"] = mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata[\"R_V_A_C_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Variance\"].astype(str) + \"_\" + mydata[\"Anisotropy\"].astype(str) + \"_\" + mydata[\"Chem\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata [\"R_C_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"Chem\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "mydata [\"R_Co\"] = mydata[\"Regime\"] + \"_\" + mydata[\"cov\"].astype(str)\n",
    "\n",
    "for g in [\"R_Co\", \"R_V_A_C_Co\"]:\n",
    "    print(g)\n",
    "    mymd = smf.mixedlm(formula = f1, data = mydata, groups = mydata[g], re_formula = '~' + xplot)\n",
    "    mdf = mymd.fit()\n",
    "    y_predict = mdf.fittedvalues\n",
    "    RMSE = np.sqrt(((y-y_predict)**2).mean())\n",
    "    row.append([yplot, xplot,g,RMSE, \"RandomFixed\"])\n",
    "\n",
    "for g in [\"PeDamark\", \"cov\"]:\n",
    "    print(g)\n",
    "    mymd = smf.mixedlm(formula = f1, data = mydata, groups = mydata[g], re_formula = '~' + xplot)\n",
    "    mdf = mymd.fit()\n",
    "    y_predict = mdf.fittedvalues\n",
    "    RMSE = np.sqrt(((y-y_predict)**2).mean())\n",
    "    row.append([yplot, xplot,g,RMSE, \"RandomFixed\"])\n",
    "    \n",
    "results = pd.DataFrame.from_records(row, columns = [\"response\", \"independent\", \"Details\", \"RMSE\", \"Model_Type\"])\n",
    "results2 = pd.DataFrame.from_records(row, columns = [\"response\", \"independent\", \"Details\", \"RMSE\", \"Model_Type\"])\n",
    "\n",
    "#LMEM is not improving the results considering PeDamark alone\n",
    "mydata.columns\n",
    "sns.scatterplot(mydata[\"Breakthroughtime\"]/mydata[\"cov\"], \"Sensitivity\", hue = \"PeDamark\", data = mydata)\n",
    "\n",
    "#Trying sci-kit learn for feature selection\n",
    "#Transient\n",
    "allfeatures = mdata.columns.tolist()\n",
    "features = ['Variance', 'Anisotropy', 'Pe', 'Chem','conc_Da', 'fraction', 'cov', 'PeDa', 'PeDamark']\n",
    "yfeature = ['Sensitivity', 'Sensitivitybase']\n",
    "\n",
    "mydata = mdata[features+yfeature]\n",
    "chemstoplot = [\"DOC\", \"DO\", \"Nitrogen\", \"TOC\"]\n",
    "mydata = mydata[mydata['Chem'].isin (chemstoplot)]\n",
    "mydata[\"Variance\"]= mydata[\"Variance\"].astype(str)\n",
    "mydata[\"Anisotropy\"]= mydata[\"Anisotropy\"].astype(str)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor as rf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "\n",
    "feattofilt = ['Variance', 'Anisotropy', 'Pe', 'conc_Da', 'fraction', 'cov']\n",
    "X = mydata[feattofilt]\n",
    "y = mydata[yfeature[0]]\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "regressor = rf(n_estimators = 20, random_state = 0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "selector = RFE (regressor, n_features_to_select = 3, step = 1)\n",
    "selector = selector.fit(X, y)\n",
    "ranking = selector.ranking_\n",
    "\n",
    "estimator = SVR(kernel = \"linear\")\n",
    "estimator.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "selector = RFE (estimator, n_features_to_select = 2, step = 1)\n",
    "selector = selector.fit(X, y)\n",
    "ranking = selector.ranking_\n",
    "\n",
    "feattofilt = ['Variance', 'Anisotropy', 'Pe', 'conc_Da', 'fraction', 'cov']\n",
    "X = mydata[feattofilt]\n",
    "y = mydata[yfeature[0]]\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, test_size = 0.2, random_state = 0)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "ols = linear_model.LinearRegression()\n",
    "svr = SVR(kernel = \"linear\")\n",
    "\n",
    "estilist = [svr, ols, lasso]\n",
    "\n",
    "for e in estilist:\n",
    "    selector = RFE(e, n_features_to_select = 2, step = 1).fit(X_train, y_train)\n",
    "    ranking = selector.ranking_\n",
    "    maxidx = list(np.where(ranking==1))\n",
    "    impfeatures = np.array(feattofilt)[maxidx].tolist()\n",
    "    print(e, \"Important features: \")\n",
    "    print(impfeatures)\n",
    "\n",
    "for e in estilist:\n",
    "    selector = SelectFromModel(e).fit(X, y)\n",
    "    ranking = selector.get_support()\n",
    "    impfeatures = np.array(feattofilt)[ranking].tolist()\n",
    "    print(e, \" Important features: \")\n",
    "    print(impfeatures)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlsm",
   "language": "python",
   "name": "mlsm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
